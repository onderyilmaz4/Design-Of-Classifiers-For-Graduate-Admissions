{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9FaHM1D8fB4"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class DecisionTreeNode():\n",
        "    def __init__(self, left, right, reference_value, output, feature_index):\n",
        "      self.left = left\n",
        "      self.right = right\n",
        "      self.reference_value = reference_value\n",
        "      self.output = output\n",
        "      self.feature_index = feature_index\n",
        "\n",
        "\n",
        "class DecisionTree(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, max_depth, min_split, depth = 0):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_split = min_split\n",
        "        self.depth = depth\n",
        "        self.root = None\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "        self.X = pd.DataFrame(X)\n",
        "        self.y = pd.DataFrame(y)\n",
        "        self.root= self.find_lowest_gini(X,y)\n",
        "\n",
        "\n",
        "  def find_lowest_gini(self, X, y):\n",
        "        lowest_gini = 1\n",
        "        best_x_left = None\n",
        "        best_x_right = None\n",
        "        best_y_left = None\n",
        "        best_y_right = None\n",
        "        best_reference_value = None\n",
        "        best_feature_index = None\n",
        "\n",
        "        n_students, n_features = X.shape\n",
        "\n",
        "        for feature_index in range(n_features):\n",
        "          list_types_of_scores = pd.unique(X.iloc[:, feature_index])\n",
        "          list_types_of_scores = sorted(list_types_of_scores)\n",
        "          n_types = len(list_types_of_scores)\n",
        "\n",
        "          if n_types == 0:\n",
        "              break\n",
        "\n",
        "          if n_types <= 2:\n",
        "            reference_value = list_types_of_scores[0]\n",
        "\n",
        "            X_left = pd.DataFrame(X[X.iloc[:, feature_index] >= reference_value])\n",
        "            X_right = pd.DataFrame(X[X.iloc[:, feature_index] < reference_value])\n",
        "\n",
        "            y_left = pd.DataFrame(y[X.iloc[:, feature_index] >= reference_value])\n",
        "            y_right = pd.DataFrame(y[X.iloc[:, feature_index] < reference_value])\n",
        "\n",
        "\n",
        "            gini_score = self.gini(y_left, y_right)\n",
        "\n",
        "            if gini_score < lowest_gini:\n",
        "                  lowest_gini = gini_score\n",
        "                  best_x_left = pd.DataFrame(X_left)\n",
        "                  best_x_right = pd.DataFrame(X_right)\n",
        "                  best_y_left = pd.DataFrame(y_left)\n",
        "                  best_y_right = pd.DataFrame(y_right)\n",
        "\n",
        "                  best_x_left.index = pd.Index(range(len(best_x_left)))\n",
        "                  best_x_right.index = pd.Index(range(len(best_x_right)))\n",
        "                  best_y_left.index = pd.Index(range(len(best_y_left)))\n",
        "                  best_y_right.index = pd.Index(range(len(best_y_right)))\n",
        "\n",
        "                  best_reference_value = reference_value\n",
        "                  best_feature_index = feature_index\n",
        "\n",
        "          else:\n",
        "            for type_in_feature in range(n_types - 1):\n",
        "                reference_value = (list_types_of_scores[type_in_feature] + list_types_of_scores[type_in_feature + 1]) / 2\n",
        "\n",
        "                X_left = X[X.iloc[:, feature_index] >= reference_value]\n",
        "                X_right = X[X.iloc[:, feature_index] < reference_value]\n",
        "\n",
        "                y_left = y[X.iloc[:, feature_index] >= reference_value]\n",
        "                y_right = y[X.iloc[:, feature_index] < reference_value]\n",
        "\n",
        "                gini_score = self.gini(y_left, y_right)\n",
        "\n",
        "                if gini_score < lowest_gini:\n",
        "                    lowest_gini = gini_score\n",
        "                    best_x_left = pd.DataFrame(X_left)\n",
        "                    best_x_right = pd.DataFrame(X_right)\n",
        "                    best_y_left = pd.DataFrame(y_left)\n",
        "                    best_y_right = pd.DataFrame(y_right)\n",
        "\n",
        "                    best_x_left.index = pd.Index(range(len(best_x_left)))\n",
        "                    best_x_right.index = pd.Index(range(len(best_x_right)))\n",
        "                    best_y_left.index = pd.Index(range(len(best_y_left)))\n",
        "                    best_y_right.index = pd.Index(range(len(best_y_right)))\n",
        "\n",
        "                    best_reference_value = reference_value\n",
        "                    best_feature_index = feature_index\n",
        "\n",
        "        return self.append_tree_check(best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y)\n",
        "\n",
        "  def append_tree_check(self, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y):\n",
        "    if best_x_left.empty or best_y_left.empty:\n",
        "        x_overall = pd.DataFrame(best_x_right)\n",
        "        y_overall = pd.DataFrame(best_y_right)\n",
        "        total_data = len(x_overall)\n",
        "\n",
        "\n",
        "    elif best_x_right.empty or best_y_right.empty:\n",
        "        x_overall = pd.DataFrame(best_x_left)\n",
        "        y_overall = pd.DataFrame(best_y_left)\n",
        "        total_data = len(x_overall)\n",
        "\n",
        "    else:\n",
        "      x_overall_temp = [best_x_left, best_x_right]\n",
        "      x_overall = pd.concat(x_overall_temp)\n",
        "      total_data = len(x_overall)\n",
        "      y_overall_temp = [best_y_left, best_y_right]\n",
        "      y_overall = pd.concat(y_overall_temp)\n",
        "\n",
        "    return self.append_tree(x_overall, y_overall, total_data, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y)\n",
        "\n",
        "  def append_tree(self, x_overall, y_overall, total_data, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value,best_feature_index, lowest_gini, y):\n",
        "\n",
        "      if total_data < self.min_split or self.depth >= self.max_depth or lowest_gini == 0 or best_x_left.empty or best_x_right.empty or best_y_left.empty or best_y_right.empty:\n",
        "        final_output = int(y_overall[\"result_1\"].mode().iloc[0])\n",
        "        return DecisionTreeNode(left = None, right = None, reference_value = None, feature_index = None, output = final_output)\n",
        "\n",
        "      else:\n",
        "        final_output = None\n",
        "        left_node = DecisionTree(max_depth = self.max_depth, min_split = self.min_split, depth = self.depth + 1)\n",
        "        right_node = DecisionTree(max_depth = self.max_depth, min_split = self.min_split, depth = self.depth + 1)\n",
        "        left_node.fit(best_x_left, best_y_left)\n",
        "        right_node.fit(best_x_right, best_y_right)\n",
        "        node = DecisionTreeNode(left = left_node, right = right_node, reference_value = best_reference_value, feature_index = best_feature_index, output = None)\n",
        "        print(node.feature_index)\n",
        "        print(node.reference_value)\n",
        "        print(node.left)\n",
        "        print(node.right)\n",
        "        return node\n",
        "\n",
        "  def gini(self, y_left, y_right):\n",
        "          y_right = pd.DataFrame(y_right)\n",
        "          y_left = pd.DataFrame(y_left)\n",
        "\n",
        "          n_students_left = len(y_left)\n",
        "          n_students_right = len(y_right)\n",
        "\n",
        "          possibilities_left = y_left.value_counts() / n_students_left\n",
        "          possibilities_right = y_right.value_counts() / n_students_right\n",
        "\n",
        "          gini_left = 1 - np.sum(possibilities_left ** 2)\n",
        "          gini_right = 1 - np.sum(possibilities_right ** 2)\n",
        "          gini_overall = (gini_left * n_students_left + gini_right * n_students_right) / (n_students_left + n_students_right)\n",
        "\n",
        "          return gini_overall\n",
        "\n",
        "  def predict(self, X):\n",
        "        predictions = []\n",
        "        for index, x in X.iterrows():\n",
        "            current_node = self.root\n",
        "            while current_node.feature_index != None:\n",
        "                if x[current_node.feature_index] < current_node.reference_value:\n",
        "                    current_node = current_node.right.root\n",
        "                elif x[current_node.feature_index] >= current_node.reference_value:\n",
        "                    current_node = current_node.left.root\n",
        "\n",
        "            predictions.append(current_node.output)\n",
        "        return np.array(predictions)\n",
        "\n",
        "  def score(self, X, y):\n",
        "        pred = self.predict(X)\n",
        "        accuracy = (pred == y).mean()\n",
        "        return accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isBnZqFYO-Hz"
      },
      "source": [
        "Stage 1 Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC2EF7p64mmS",
        "outputId": "9722c5bb-2ff5-41bc-d7cd-797dbed717c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.87850467 0.85046729 0.89622642 0.88679245 0.81132075]\n",
            "Mean cv score:  0.8646623170516664\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Read the data from the Excel file\n",
        "df = pd.read_excel(\"final_data492_collab.xlsx\", decimal=',')\n",
        "\n",
        "# Step 2: Drop unnecessary columns and separate features and target variable\n",
        "df_dropped = df.drop(columns=['interview_score', 'result_2', 'year'])\n",
        "X = df_dropped.drop(columns=['result_1'])\n",
        "y = df_dropped['result_1']\n",
        "\n",
        "\n",
        "# Step 3: Standardize the feature values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
        "\n",
        "\n",
        "stage_1_tree = DecisionTree(min_split = 9, max_depth = 14, depth = 0)\n",
        "cv_scores = cross_val_score(stage_1_tree, X, y, cv=5)  # 5-fold cross-validation\n",
        "\n",
        "print(cv_scores)\n",
        "print(\"Mean cv score: \", cv_scores.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JDhSw_vUfgT"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class DecisionTreeNode():\n",
        "    def __init__(self, left, right, reference_value, output, feature_index):\n",
        "      self.left = left\n",
        "      self.right = right\n",
        "      self.reference_value = reference_value\n",
        "      self.output = output\n",
        "      self.feature_index = feature_index\n",
        "\n",
        "\n",
        "class DecisionTree(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, max_depth, min_split, depth = 0):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_split = min_split\n",
        "        self.depth = depth\n",
        "        self.root = None\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "        self.X = pd.DataFrame(X)\n",
        "        self.y = pd.DataFrame(y)\n",
        "        self.root= self.find_lowest_gini(X,y)\n",
        "\n",
        "\n",
        "  def find_lowest_gini(self, X, y):\n",
        "        lowest_gini = 1\n",
        "        best_x_left = None\n",
        "        best_x_right = None\n",
        "        best_y_left = None\n",
        "        best_y_right = None\n",
        "        best_reference_value = None\n",
        "        best_feature_index = None\n",
        "\n",
        "        n_students, n_features = X.shape\n",
        "\n",
        "        for feature_index in range(n_features):\n",
        "          list_types_of_scores = pd.unique(X.iloc[:, feature_index])\n",
        "          list_types_of_scores = sorted(list_types_of_scores)\n",
        "          n_types = len(list_types_of_scores)\n",
        "\n",
        "          if n_types == 0:\n",
        "              break\n",
        "\n",
        "          if n_types <= 2:\n",
        "            reference_value = list_types_of_scores[0]\n",
        "\n",
        "            X_left = pd.DataFrame(X[X.iloc[:, feature_index] >= reference_value])\n",
        "            X_right = pd.DataFrame(X[X.iloc[:, feature_index] < reference_value])\n",
        "\n",
        "            y_left = pd.DataFrame(y[X.iloc[:, feature_index] >= reference_value])\n",
        "            y_right = pd.DataFrame(y[X.iloc[:, feature_index] < reference_value])\n",
        "\n",
        "\n",
        "            gini_score = self.gini(y_left, y_right)\n",
        "\n",
        "            if gini_score < lowest_gini:\n",
        "                  lowest_gini = gini_score\n",
        "                  best_x_left = pd.DataFrame(X_left)\n",
        "                  best_x_right = pd.DataFrame(X_right)\n",
        "                  best_y_left = pd.DataFrame(y_left)\n",
        "                  best_y_right = pd.DataFrame(y_right)\n",
        "\n",
        "                  best_x_left.index = pd.Index(range(len(best_x_left)))\n",
        "                  best_x_right.index = pd.Index(range(len(best_x_right)))\n",
        "                  best_y_left.index = pd.Index(range(len(best_y_left)))\n",
        "                  best_y_right.index = pd.Index(range(len(best_y_right)))\n",
        "\n",
        "                  best_reference_value = reference_value\n",
        "                  best_feature_index = feature_index\n",
        "\n",
        "          else:\n",
        "            for type_in_feature in range(n_types - 1):\n",
        "                reference_value = (list_types_of_scores[type_in_feature] + list_types_of_scores[type_in_feature + 1]) / 2\n",
        "\n",
        "                X_left = X[X.iloc[:, feature_index] >= reference_value]\n",
        "                X_right = X[X.iloc[:, feature_index] < reference_value]\n",
        "\n",
        "                y_left = y[X.iloc[:, feature_index] >= reference_value]\n",
        "                y_right = y[X.iloc[:, feature_index] < reference_value]\n",
        "\n",
        "                gini_score = self.gini(y_left, y_right)\n",
        "\n",
        "                if gini_score < lowest_gini:\n",
        "                    lowest_gini = gini_score\n",
        "                    best_x_left = pd.DataFrame(X_left)\n",
        "                    best_x_right = pd.DataFrame(X_right)\n",
        "                    best_y_left = pd.DataFrame(y_left)\n",
        "                    best_y_right = pd.DataFrame(y_right)\n",
        "\n",
        "                    best_x_left.index = pd.Index(range(len(best_x_left)))\n",
        "                    best_x_right.index = pd.Index(range(len(best_x_right)))\n",
        "                    best_y_left.index = pd.Index(range(len(best_y_left)))\n",
        "                    best_y_right.index = pd.Index(range(len(best_y_right)))\n",
        "\n",
        "                    best_reference_value = reference_value\n",
        "                    best_feature_index = feature_index\n",
        "\n",
        "        return self.append_tree_check(best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y)\n",
        "\n",
        "  def append_tree_check(self, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y):\n",
        "    if best_x_left.empty or best_y_left.empty:\n",
        "        x_overall = pd.DataFrame(best_x_right)\n",
        "        y_overall = pd.DataFrame(best_y_right)\n",
        "        total_data = len(x_overall)\n",
        "\n",
        "\n",
        "    elif best_x_right.empty or best_y_right.empty:\n",
        "        x_overall = pd.DataFrame(best_x_left)\n",
        "        y_overall = pd.DataFrame(best_y_left)\n",
        "        total_data = len(x_overall)\n",
        "\n",
        "    else:\n",
        "      x_overall_temp = [best_x_left, best_x_right]\n",
        "      x_overall = pd.concat(x_overall_temp)\n",
        "      total_data = len(x_overall)\n",
        "      y_overall_temp = [best_y_left, best_y_right]\n",
        "      y_overall = pd.concat(y_overall_temp)\n",
        "\n",
        "    return self.append_tree(x_overall, y_overall, total_data, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y)\n",
        "\n",
        "  def append_tree(self, x_overall, y_overall, total_data, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value,best_feature_index, lowest_gini, y):\n",
        "\n",
        "      if total_data < self.min_split or self.depth >= self.max_depth or lowest_gini == 0 or best_x_left.empty or best_x_right.empty or best_y_left.empty or best_y_right.empty:\n",
        "        final_output = int(y_overall[0].mode().iloc[0])\n",
        "        return DecisionTreeNode(left = None, right = None, reference_value = None, feature_index = None, output = final_output)\n",
        "\n",
        "      else:\n",
        "        final_output = None\n",
        "        left_node = DecisionTree(max_depth = self.max_depth, min_split = self.min_split, depth = self.depth + 1)\n",
        "        right_node = DecisionTree(max_depth = self.max_depth, min_split = self.min_split, depth = self.depth + 1)\n",
        "        left_node.fit(best_x_left, best_y_left)\n",
        "        right_node.fit(best_x_right, best_y_right)\n",
        "        node = DecisionTreeNode(left = left_node, right = right_node, reference_value = best_reference_value, feature_index = best_feature_index, output = None)\n",
        "        print(node.feature_index)\n",
        "        print(node.reference_value)\n",
        "        print(node.left)\n",
        "        print(node.right)\n",
        "        return node\n",
        "\n",
        "\n",
        "  def gini(self, y_left, y_right):\n",
        "          y_right = pd.DataFrame(y_right)\n",
        "          y_left = pd.DataFrame(y_left)\n",
        "\n",
        "          n_students_left = len(y_left)\n",
        "          n_students_right = len(y_right)\n",
        "\n",
        "          possibilities_left = y_left.value_counts() / n_students_left\n",
        "          possibilities_right = y_right.value_counts() / n_students_right\n",
        "\n",
        "          gini_left = 1 - np.sum(possibilities_left ** 2)\n",
        "          gini_right = 1 - np.sum(possibilities_right ** 2)\n",
        "          gini_overall = (gini_left * n_students_left + gini_right * n_students_right) / (n_students_left + n_students_right)\n",
        "\n",
        "          return gini_overall\n",
        "\n",
        "  def predict(self, X):\n",
        "        predictions = []\n",
        "        for index, x in X.iterrows():\n",
        "            current_node = self.root\n",
        "            while current_node.feature_index != None:\n",
        "                if x[current_node.feature_index] < current_node.reference_value:\n",
        "                    current_node = current_node.right.root\n",
        "                elif x[current_node.feature_index] >= current_node.reference_value:\n",
        "                    current_node = current_node.left.root\n",
        "\n",
        "            predictions.append(current_node.output)\n",
        "        return np.array(predictions)\n",
        "\n",
        "  def predict(self, X):\n",
        "        predictions = []\n",
        "        for index, x in X.iterrows():\n",
        "            current_node = self.root\n",
        "            while current_node.feature_index != None:\n",
        "                if x[current_node.feature_index] < current_node.reference_value:\n",
        "                    current_node = current_node.right.root\n",
        "                elif x[current_node.feature_index] >= current_node.reference_value:\n",
        "                    current_node = current_node.left.root\n",
        "\n",
        "            predictions.append(current_node.output)\n",
        "        return np.array(predictions)\n",
        "\n",
        "  def score(self, X, y):\n",
        "        pred = self.predict(X)\n",
        "        accuracy = (pred == y).mean()\n",
        "        return accuracy, pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W9jl8U1lqco",
        "outputId": "d992bfdb-8d4f-4cec-e7f6-44a1f7d63e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "91.71000289916992\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "4\n",
            "94.75\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "3\n",
            "3.515\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "5\n",
            "437.51181\n",
            "DecisionTree(depth=3, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=3, max_depth=14, min_split=9)\n",
            "3\n",
            "2.865\n",
            "DecisionTree(depth=6, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=6, max_depth=14, min_split=9)\n",
            "3\n",
            "2.625\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "4\n",
            "93.292135\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "5\n",
            "480.320915\n",
            "DecisionTree(depth=3, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=3, max_depth=14, min_split=9)\n",
            "3\n",
            "2.915\n",
            "DecisionTree(depth=2, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=2, max_depth=14, min_split=9)\n",
            "3\n",
            "3.0\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "4\n",
            "84.84500122070312\n",
            "DecisionTree(depth=7, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=7, max_depth=14, min_split=9)\n",
            "4\n",
            "86.71379833333333\n",
            "DecisionTree(depth=6, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=6, max_depth=14, min_split=9)\n",
            "4\n",
            "89.59591030517578\n",
            "DecisionTree(depth=7, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=7, max_depth=14, min_split=9)\n",
            "4\n",
            "83.03256999999999\n",
            "DecisionTree(depth=9, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=9, max_depth=14, min_split=9)\n",
            "3\n",
            "2.75\n",
            "DecisionTree(depth=8, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=8, max_depth=14, min_split=9)\n",
            "5\n",
            "366.96664681818186\n",
            "DecisionTree(depth=7, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=7, max_depth=14, min_split=9)\n",
            "4\n",
            "83.27355423706055\n",
            "DecisionTree(depth=6, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=6, max_depth=14, min_split=9)\n",
            "3\n",
            "3.4450000000000003\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "3\n",
            "2.54\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "5\n",
            "518.9569349999999\n",
            "DecisionTree(depth=3, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=3, max_depth=14, min_split=9)\n",
            "3\n",
            "3.395\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "4\n",
            "35.23500061035156\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "3\n",
            "2.91\n",
            "DecisionTree(depth=6, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=6, max_depth=14, min_split=9)\n",
            "4\n",
            "38.7\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "3\n",
            "3.2350000000000003\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=5, max_depth=14, min_split=9)\n",
            "5\n",
            "434.09925999999996\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=4, max_depth=14, min_split=9)\n",
            "3\n",
            "3.325\n",
            "DecisionTree(depth=3, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=3, max_depth=14, min_split=9)\n",
            "4\n",
            "80.232745\n",
            "DecisionTree(depth=2, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=2, max_depth=14, min_split=9)\n",
            "4\n",
            "90.33907500000001\n",
            "DecisionTree(depth=1, max_depth=14, min_split=9)\n",
            "DecisionTree(depth=1, max_depth=14, min_split=9)\n",
            "Accuracy: 0.8785046728971962\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.95        39\n",
            "           1       0.64      0.69      0.67        13\n",
            "           2       0.88      0.89      0.88        55\n",
            "\n",
            "    accuracy                           0.88       107\n",
            "   macro avg       0.83      0.84      0.83       107\n",
            "weighted avg       0.88      0.88      0.88       107\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Read the data, specifying the decimal separator\n",
        "df = pd.read_excel(\"final_data492_collab.xlsx\", decimal=',')\n",
        "\n",
        "# Step 2: Separate features and target variable\n",
        "X = df.drop(columns=['result_1'])\n",
        "y = df['result_1'].values\n",
        "\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Step 4: Store the dropped columns and drop them from the training and testing sets\n",
        "dropped_columns_train = X_train[['year', 'result_2', 'interview_score']]\n",
        "dropped_columns_test = X_test[['year', 'result_2',  'interview_score']]\n",
        "\n",
        "X_train.drop(columns=['year', 'result_2','interview_score'], inplace = True)\n",
        "X_test.drop(columns=['year', 'result_2', 'interview_score'], inplace = True)\n",
        "\n",
        "# Step 5: Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train))\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test))\n",
        "\n",
        "\n",
        "# Step 6: Fit the model, make predictions, and calculate the accuracy\n",
        "stage_1_tree = DecisionTree(min_split = 9, max_depth = 14, depth = 0)\n",
        "stage_1_tree.fit(X_train, y_train) # X_train_scaled\n",
        "accuracy, pred = stage_1_tree.score(X_test, y_test) # x_test_scaled\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, pred)\n",
        "\n",
        "# Print the report\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Step 7: Merge predictions, actual labels, and features with dropped columns\n",
        "results_df = pd.DataFrame({'Predicted_Result_1': pred, 'Actual_Result_1': y_test})\n",
        "X_test_df = pd.DataFrame(X_test, columns=X_test.columns)  # Convert X_test array to DataFrame\n",
        "results_df = pd.concat([results_df, X_test_df.reset_index(drop=True), dropped_columns_test.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Step 9: Save to Excel\n",
        "results_df.to_excel('final_data_with_predictions_stage_1.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3IpYlbPPjCE"
      },
      "source": [
        "Stage 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr0zWRMfg_cQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class DecisionTreeNode():\n",
        "    def __init__(self, left, right, reference_value, output, feature_index):\n",
        "      self.left = left\n",
        "      self.right = right\n",
        "      self.reference_value = reference_value\n",
        "      self.output = output\n",
        "      self.feature_index = feature_index\n",
        "\n",
        "\n",
        "class DecisionTree(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, max_depth, min_split, depth = 0):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_split = min_split\n",
        "        self.depth = depth\n",
        "        self.root = None\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "        self.X = pd.DataFrame(X)\n",
        "        self.y = pd.DataFrame(y)\n",
        "        self.root= self.find_lowest_gini(X,y)\n",
        "\n",
        "\n",
        "  def find_lowest_gini(self, X, y):\n",
        "        lowest_gini = 1\n",
        "        best_x_left = None\n",
        "        best_x_right = None\n",
        "        best_y_left = None\n",
        "        best_y_right = None\n",
        "        best_reference_value = None\n",
        "        best_feature_index = None\n",
        "\n",
        "        n_students, n_features = X.shape\n",
        "\n",
        "        for feature_index in range(n_features):\n",
        "          list_types_of_scores = pd.unique(X.iloc[:, feature_index])\n",
        "          list_types_of_scores = sorted(list_types_of_scores)\n",
        "          n_types = len(list_types_of_scores)\n",
        "\n",
        "          if n_types == 0:\n",
        "              break\n",
        "\n",
        "          if n_types <= 2:\n",
        "            reference_value = list_types_of_scores[0]\n",
        "\n",
        "            X_left = pd.DataFrame(X[X.iloc[:, feature_index] >= reference_value])\n",
        "            X_right = pd.DataFrame(X[X.iloc[:, feature_index] < reference_value])\n",
        "\n",
        "            y_left = pd.DataFrame(y[X.iloc[:, feature_index] >= reference_value])\n",
        "            y_right = pd.DataFrame(y[X.iloc[:, feature_index] < reference_value])\n",
        "\n",
        "\n",
        "            gini_score = self.gini(y_left, y_right)\n",
        "\n",
        "            if gini_score < lowest_gini:\n",
        "                  lowest_gini = gini_score\n",
        "                  best_x_left = pd.DataFrame(X_left)\n",
        "                  best_x_right = pd.DataFrame(X_right)\n",
        "                  best_y_left = pd.DataFrame(y_left)\n",
        "                  best_y_right = pd.DataFrame(y_right)\n",
        "                  best_reference_value = reference_value\n",
        "                  best_feature_index = feature_index\n",
        "\n",
        "                  best_x_left.index = pd.Index(range(len(best_x_left)))\n",
        "                  best_x_right.index = pd.Index(range(len(best_x_right)))\n",
        "                  best_y_left.index = pd.Index(range(len(best_y_left)))\n",
        "                  best_y_right.index = pd.Index(range(len(best_y_right)))\n",
        "\n",
        "          else:\n",
        "            for type_in_feature in range(n_types - 1):\n",
        "                reference_value = (list_types_of_scores[type_in_feature] + list_types_of_scores[type_in_feature + 1]) / 2\n",
        "\n",
        "                X_left = X[X.iloc[:, feature_index] >= reference_value]\n",
        "                X_right = X[X.iloc[:, feature_index] < reference_value]\n",
        "\n",
        "                y_left = y[X.iloc[:, feature_index] >= reference_value]\n",
        "                y_right = y[X.iloc[:, feature_index] < reference_value]\n",
        "\n",
        "                gini_score = self.gini(y_left, y_right)\n",
        "\n",
        "                if gini_score < lowest_gini:\n",
        "                    lowest_gini = gini_score\n",
        "                    best_x_left = pd.DataFrame(X_left)\n",
        "                    best_x_right = pd.DataFrame(X_right)\n",
        "                    best_y_left = pd.DataFrame(y_left)\n",
        "                    best_y_right = pd.DataFrame(y_right)\n",
        "\n",
        "                    best_x_left.index = pd.Index(range(len(best_x_left)))\n",
        "                    best_x_right.index = pd.Index(range(len(best_x_right)))\n",
        "                    best_y_left.index = pd.Index(range(len(best_y_left)))\n",
        "                    best_y_right.index = pd.Index(range(len(best_y_right)))\n",
        "\n",
        "                    best_reference_value = reference_value\n",
        "                    best_feature_index = feature_index\n",
        "\n",
        "\n",
        "        return self.append_tree_check(best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y)\n",
        "\n",
        "  def append_tree_check(self, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y):\n",
        "    if best_x_left.empty or best_y_left.empty:\n",
        "        x_overall = pd.DataFrame(best_x_right)\n",
        "        y_overall = pd.DataFrame(best_y_right)\n",
        "        total_data = len(x_overall)\n",
        "\n",
        "\n",
        "    elif best_x_right.empty or best_y_right.empty:\n",
        "        x_overall = pd.DataFrame(best_x_left)\n",
        "        y_overall = pd.DataFrame(best_y_left)\n",
        "        total_data = len(x_overall)\n",
        "\n",
        "    else:\n",
        "      x_overall_temp = [best_x_left, best_x_right]\n",
        "      x_overall = pd.concat(x_overall_temp)\n",
        "      total_data = len(x_overall)\n",
        "      y_overall_temp = [best_y_left, best_y_right]\n",
        "      y_overall = pd.concat(y_overall_temp)\n",
        "\n",
        "    return self.append_tree(x_overall, y_overall, total_data, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y)\n",
        "\n",
        "  def append_tree(self, x_overall, y_overall, total_data, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value,best_feature_index, lowest_gini, y):\n",
        "\n",
        "      if total_data < self.min_split or self.depth >= self.max_depth or lowest_gini == 0 :\n",
        "\n",
        "        final_output = int(y_overall[0].mode().iloc[0])\n",
        "        return DecisionTreeNode(left = None, right = None, reference_value = None, feature_index = None, output = final_output)\n",
        "\n",
        "      else:\n",
        "        final_output = None\n",
        "        left_node = DecisionTree(max_depth = self.max_depth, min_split = self.min_split, depth = self.depth + 1)\n",
        "        right_node = DecisionTree(max_depth = self.max_depth, min_split = self.min_split, depth = self.depth + 1)\n",
        "        left_node.fit(best_x_left, best_y_left)\n",
        "        right_node.fit(best_x_right, best_y_right)\n",
        "        return DecisionTreeNode(left = left_node, right = right_node, reference_value = best_reference_value, feature_index = best_feature_index, output = None)\n",
        "\n",
        "  def gini(self, y_left, y_right):\n",
        "          y_right = pd.DataFrame(y_right)\n",
        "          y_left = pd.DataFrame(y_left)\n",
        "\n",
        "          n_students_left = len(y_left)\n",
        "          n_students_right = len(y_right)\n",
        "\n",
        "          possibilities_left = y_left.value_counts() / n_students_left\n",
        "          possibilities_right = y_right.value_counts() / n_students_right\n",
        "\n",
        "          gini_left = 1 - np.sum(possibilities_left ** 2)\n",
        "          gini_right = 1 - np.sum(possibilities_right ** 2)\n",
        "          gini_overall = (gini_left * n_students_left + gini_right * n_students_right) / (n_students_left + n_students_right)\n",
        "\n",
        "          return gini_overall\n",
        "\n",
        "  def predict(self, X):\n",
        "        predictions = []\n",
        "        for index, x in X.iterrows():\n",
        "            current_node = self.root\n",
        "            while current_node.feature_index != None:\n",
        "                if x[current_node.feature_index] < current_node.reference_value:\n",
        "                    current_node = current_node.right.root\n",
        "                elif x[current_node.feature_index] >= current_node.reference_value:\n",
        "                    current_node = current_node.left.root\n",
        "\n",
        "            predictions.append(current_node.output)\n",
        "        return np.array(predictions)\n",
        "\n",
        "  def score(self, X, y):\n",
        "\n",
        "        pred = self.predict(X)\n",
        "        accuracy = (pred == y[0]).mean()\n",
        "\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H-m31z5RT_a",
        "outputId": "05246502-1836-4528-db75-22e1381a0804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9375     0.9375     0.77083333 0.91666667 0.8125    ]\n",
            "Mean CV Score: 0.875\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_excel(\"final_data492_collab.xlsx\", decimal=',')\n",
        "\n",
        "df_interview = df[df[\"result_1\"] == 2].copy()\n",
        "df_interview.dropna(inplace=True)\n",
        "\n",
        "df_interview.drop(columns=['result_1', 'year'], inplace=True)\n",
        "\n",
        "X = df_interview.drop(columns=['result_2']).values\n",
        "y = df_interview['result_2'].values\n",
        "\n",
        "X = pd.DataFrame(X)\n",
        "y = pd.DataFrame(y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled)\n",
        "\n",
        "stage_2_tree = DecisionTree(min_split = 9, max_depth = 14, depth = 0)\n",
        "cv_scores = cross_val_score(stage_2_tree, X_scaled, y, cv=5)  # 5-fold cross-validation\n",
        "\n",
        "print(cv_scores)\n",
        "print(\"Mean CV Score:\", cv_scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amo8N-xSjTZI"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "class DecisionTreeNode():\n",
        "    def __init__(self, left, right, reference_value, output, feature_index):\n",
        "      self.left = left\n",
        "      self.right = right\n",
        "      self.reference_value = reference_value\n",
        "      self.output = output\n",
        "      self.feature_index = feature_index\n",
        "\n",
        "\n",
        "class DecisionTree(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, max_depth, min_split, depth = 0):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_split = min_split\n",
        "        self.depth = depth\n",
        "        self.root = None\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "        self.X = pd.DataFrame(X)\n",
        "        self.y = pd.DataFrame(y)\n",
        "        self.root= self.find_lowest_gini(X,y)\n",
        "\n",
        "\n",
        "  def find_lowest_gini(self, X, y):\n",
        "        lowest_gini = 1\n",
        "        best_x_left = None\n",
        "        best_x_right = None\n",
        "        best_y_left = None\n",
        "        best_y_right = None\n",
        "        best_reference_value = None\n",
        "        best_feature_index = None\n",
        "\n",
        "        n_students, n_features = X.shape\n",
        "\n",
        "        for feature_index in range(n_features):\n",
        "          list_types_of_scores = pd.unique(X.iloc[:, feature_index])\n",
        "          list_types_of_scores = sorted(list_types_of_scores)\n",
        "          n_types = len(list_types_of_scores)\n",
        "\n",
        "          if n_types == 0:\n",
        "              break\n",
        "\n",
        "          if n_types <= 2:\n",
        "            reference_value = list_types_of_scores[0]\n",
        "\n",
        "            X_left = pd.DataFrame(X[X.iloc[:, feature_index] >= reference_value])\n",
        "            X_right = pd.DataFrame(X[X.iloc[:, feature_index] < reference_value])\n",
        "\n",
        "            y_left = pd.DataFrame(y[X.iloc[:, feature_index] >= reference_value])\n",
        "            y_right = pd.DataFrame(y[X.iloc[:, feature_index] < reference_value])\n",
        "\n",
        "\n",
        "            gini_score = self.gini(y_left, y_right)\n",
        "\n",
        "            if gini_score < lowest_gini:\n",
        "                  lowest_gini = gini_score\n",
        "                  best_x_left = pd.DataFrame(X_left)\n",
        "                  best_x_right = pd.DataFrame(X_right)\n",
        "                  best_y_left = pd.DataFrame(y_left)\n",
        "                  best_y_right = pd.DataFrame(y_right)\n",
        "                  best_reference_value = reference_value\n",
        "                  best_feature_index = feature_index\n",
        "\n",
        "                  best_x_left.index = pd.Index(range(len(best_x_left)))\n",
        "                  best_x_right.index = pd.Index(range(len(best_x_right)))\n",
        "                  best_y_left.index = pd.Index(range(len(best_y_left)))\n",
        "                  best_y_right.index = pd.Index(range(len(best_y_right)))\n",
        "\n",
        "          else:\n",
        "            for type_in_feature in range(n_types - 1):\n",
        "                reference_value = (list_types_of_scores[type_in_feature] + list_types_of_scores[type_in_feature + 1]) / 2\n",
        "\n",
        "                X_left = X[X.iloc[:, feature_index] >= reference_value]\n",
        "                X_right = X[X.iloc[:, feature_index] < reference_value]\n",
        "\n",
        "                y_left = y[X.iloc[:, feature_index] >= reference_value]\n",
        "                y_right = y[X.iloc[:, feature_index] < reference_value]\n",
        "\n",
        "                gini_score = self.gini(y_left, y_right)\n",
        "\n",
        "                if gini_score < lowest_gini:\n",
        "                    lowest_gini = gini_score\n",
        "                    best_x_left = pd.DataFrame(X_left)\n",
        "                    best_x_right = pd.DataFrame(X_right)\n",
        "                    best_y_left = pd.DataFrame(y_left)\n",
        "                    best_y_right = pd.DataFrame(y_right)\n",
        "\n",
        "                    best_x_left.index = pd.Index(range(len(best_x_left)))\n",
        "                    best_x_right.index = pd.Index(range(len(best_x_right)))\n",
        "                    best_y_left.index = pd.Index(range(len(best_y_left)))\n",
        "                    best_y_right.index = pd.Index(range(len(best_y_right)))\n",
        "\n",
        "                    best_reference_value = reference_value\n",
        "                    best_feature_index = feature_index\n",
        "\n",
        "        return self.append_tree_check(best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y)\n",
        "\n",
        "  def append_tree_check(self, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y):\n",
        "    if best_x_left.empty or best_y_left.empty:\n",
        "        x_overall = pd.DataFrame(best_x_right)\n",
        "        y_overall = pd.DataFrame(best_y_right)\n",
        "        total_data = len(x_overall)\n",
        "\n",
        "\n",
        "    elif best_x_right.empty or best_y_right.empty:\n",
        "        x_overall = pd.DataFrame(best_x_left)\n",
        "        y_overall = pd.DataFrame(best_y_left)\n",
        "        total_data = len(x_overall)\n",
        "\n",
        "    else:\n",
        "      x_overall_temp = [best_x_left, best_x_right]\n",
        "      x_overall = pd.concat(x_overall_temp)\n",
        "      total_data = len(x_overall)\n",
        "      y_overall_temp = [best_y_left, best_y_right]\n",
        "      y_overall = pd.concat(y_overall_temp)\n",
        "\n",
        "    return self.append_tree(x_overall, y_overall, total_data, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value, best_feature_index, lowest_gini, y)\n",
        "\n",
        "  def append_tree(self, x_overall, y_overall, total_data, best_x_left, best_x_right, best_y_left, best_y_right, best_reference_value,best_feature_index, lowest_gini, y):\n",
        "\n",
        "      if total_data < self.min_split or self.depth >= self.max_depth or lowest_gini == 0 :\n",
        "\n",
        "        final_output = int(y_overall[0].mode().iloc[0])\n",
        "        return DecisionTreeNode(left = None, right = None, reference_value = None, feature_index = None, output = final_output)\n",
        "\n",
        "      else:\n",
        "        final_output = None\n",
        "        left_node = DecisionTree(max_depth = self.max_depth, min_split = self.min_split, depth = self.depth + 1)\n",
        "        right_node = DecisionTree(max_depth = self.max_depth, min_split = self.min_split, depth = self.depth + 1)\n",
        "        left_node.fit(best_x_left, best_y_left)\n",
        "        right_node.fit(best_x_right, best_y_right)\n",
        "        return DecisionTreeNode(left = left_node, right = right_node, reference_value = best_reference_value, feature_index = best_feature_index, output = None)\n",
        "\n",
        "  def gini(self, y_left, y_right):\n",
        "          y_right = pd.DataFrame(y_right)\n",
        "          y_left = pd.DataFrame(y_left)\n",
        "\n",
        "          n_students_left = len(y_left)\n",
        "          n_students_right = len(y_right)\n",
        "\n",
        "          possibilities_left = y_left.value_counts() / n_students_left\n",
        "          possibilities_right = y_right.value_counts() / n_students_right\n",
        "\n",
        "          gini_left = 1 - np.sum(possibilities_left ** 2)\n",
        "          gini_right = 1 - np.sum(possibilities_right ** 2)\n",
        "          gini_overall = (gini_left * n_students_left + gini_right * n_students_right) / (n_students_left + n_students_right)\n",
        "\n",
        "          return gini_overall\n",
        "\n",
        "  def predict(self, X):\n",
        "        predictions = []\n",
        "        for index, x in X.iterrows():\n",
        "            current_node = self.root\n",
        "            while current_node.feature_index != None:\n",
        "                if x[current_node.feature_index] < current_node.reference_value:\n",
        "                    current_node = current_node.right.root\n",
        "                elif x[current_node.feature_index] >= current_node.reference_value:\n",
        "                    current_node = current_node.left.root\n",
        "\n",
        "            predictions.append(current_node.output)\n",
        "        return np.array(predictions)\n",
        "\n",
        "  def score(self, X, y):\n",
        "\n",
        "        pred = self.predict(X)\n",
        "        accuracy = (pred == y[0]).mean()\n",
        "\n",
        "        return accuracy, pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2_jk_7PPlMv",
        "outputId": "f50aa2f9-c36d-4780-fd6d-0f571daa82d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.90      0.88        21\n",
            "         1.0       0.92      0.89      0.91        27\n",
            "\n",
            "    accuracy                           0.90        48\n",
            "   macro avg       0.89      0.90      0.89        48\n",
            "weighted avg       0.90      0.90      0.90        48\n",
            "\n",
            "0.8958333333333334\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_excel(\"final_data492_collab.xlsx\", decimal=',')\n",
        "\n",
        "df_interview = df[df[\"result_1\"] == 2].copy()\n",
        "df_interview.dropna(inplace=True)\n",
        "\n",
        "df_interview.drop(columns=['result_1', 'year'], inplace=True)\n",
        "\n",
        "X = df_interview.drop(columns=['result_2']).values\n",
        "y = df_interview['result_2'].values\n",
        "\n",
        "X = pd.DataFrame(X)\n",
        "y = pd.DataFrame(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "\n",
        "stage_2_tree = DecisionTree(min_split = 9, max_depth = 14, depth = 0)\n",
        "\n",
        "stage_2_tree.fit(X_train, y_train)\n",
        "\n",
        "accuracy, pred = stage_2_tree.score(X_test, y_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, pred)\n",
        "\n",
        "# Print the report\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(accuracy)\n",
        "\n",
        "# Step 7: Merge predictions, actual labels, and features with dropped columns\n",
        "results_df = pd.DataFrame({'Predicted_Result_2': pred, 'Actual_Result_2': y_test[0]})\n",
        "X_test_df = pd.DataFrame(X_test, columns=X_test.columns)  # Convert X_test array to DataFrame\n",
        "results_df = pd.concat([results_df, X_test_df], axis=1)\n",
        "\n",
        "# Step 9: Save to Excel\n",
        "results_df.to_excel('final_data_with_predictions_stage_2.xlsx', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}